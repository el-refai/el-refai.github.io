<!DOCTYPE HTML>
<html lang="en">
<head>
  <!-- Google tag (gtag.js)
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-S4T4PFRZVD"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-S4T4PFRZVD');
  </script> -->
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Karim El-Refai</title>
  
  <meta name="author" content="Karim El-Refai">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Karim El-Refai</name>
              </p>
              <p>
                I am a fourth year undergraduate student at UC Berkeley advised by Professor <a href="https://goldberg.berkeley.edu/">Ken Goldberg</a>. 
                I am interested in building perception systems for language-guided robot interaction and manipulation. 
              </p>
              <p style="text-align:center">
                <a href="mailto:karim.el-refai@berkeley.edu">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=OC3OLioAAAAJ&hl">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/karim-el-refai/">LinkedIn</a> &nbsp/&nbsp
                <a href="resume.pdf">Resume</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/niagara.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/niagara.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <!-- LEGS -->
          <tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one" style="max-width: 100%; height: auto; overflow: hidden;">
                <img src="images/legs_splash.png" style="width: 100%; height: auto; max-width: 500px;">
              </div>
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <!-- TITLE -->
              <a href="https://berkeleyautomation.github.io/LEGS/"><papertitle>LEGS: Incrementally Building Room-Scale Language-Embedded Gaussian Splats with a Mobile Robot</papertitle></a>
              <br>
              <!-- AUTHORS -->
              Justin Yu*, Kush Hari*, Kishore Srinivas*, <b>Karim El-Refai</b>, Adam Rashid, Chung Min Kim, Justin Kerr, Richard Cheng, Ashwin Balakrishna, Thomas Kollar, Ken Goldberg
              <br>
              *Equal contribution
              <br>
              <!-- CONFERENCE -->
              <em>IROS</em> 2024 <font color="red"><strong>(Oral Presentation)</strong></font>
              <!-- LINKS -->
              <br>
              <a href="https://arxiv.org/abs/2409.18108">arXiv</a> / <a href="https://berkeleyautomation.github.io/LEGS/">Website</a>
              <p></p>
              <!-- SUMMARY -->
              LEGS provides detailed 3D scene representation that encodes both appearance and semantics in a unified representation while being able to be trained online as a robot traverses its environment to enable localization of open-vocabulary object queries.
            </td>
          </tr>
          <!-- SWAG -->
          <tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one" style="max-width: 100%; height: auto; overflow: hidden;">
                <img src="images/swag_inference.png" style="width: 100%; height: auto; max-width: 500px;">
              </div>
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <!-- TITLE -->
              <a href="https://arxiv.org/abs/2402.03483"><papertitle>SWAG: Storytelling With Action Guidance</papertitle></a>
              <br>
              <!-- AUTHORS -->
              Zeeshan Patel*, <b>Karim El-Refai*</b>, Jonathan Pei*, Tianle Li
              <br>
              *Equal contribution
              <br>
              <!-- CONFERENCE -->
              <em>EMNLP Findings</em> 2024
              <br>
              <a href="https://arxiv.org/abs/2402.03483">arXiv</a>
              <p></p>
              <!-- SUMMARY -->
              SWAG is a novel approach to storytelling with LLMs which reduces story writing to a search problem through a two-model feedback loop. SWAG can substantially outperform previous end-to-end story generation techniques when evaluated by GPT-4 and through human evaluation, and our SWAG pipeline using only open-source models surpasses GPT-3.5- Turbo. 
            </td>
          </tr>
          <!-- Gasket Assembly -->
          <tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one" style="max-width: 100%; height: auto; overflow: hidden;">
                <img src="images/gasket_splash.png" style="width: 100%; height: auto; max-width: 500px;">
              </div>
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <!-- TITLE -->
              <a href="https://arxiv.org/abs/2408.12593"><papertitle>Automating Deformable Gasket Assembly</papertitle></a>
              <br>
              <!-- AUTHORS -->
              Simeon Adebola*, Tara Sadjadpour*, <b>Karim El-Refai*</b>, Will Panitch, Zehan Ma, Roy Lin, Tianshuang Qiu, Shreya Ganti, Charlotte Le, Jaimyn Drake, Ken Goldberg
              <br>
              <!-- CONFERENCE -->
              <em>CASE</em> 2024
              <br>
              *Equal contribution
              <br>
              <a href="https://arxiv.org/abs/2408.12593">arXiv</a>
              <p></p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <p>
                Source code taken from <a href="https://jonbarron.info/">Jon Barron's site.</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>